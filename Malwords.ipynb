{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dimensionality_reduction import dr_action\n",
    "from classification import cla_action\n",
    "from visualization import vis_action\n",
    "from preprocessing import pp_action\n",
    "from clustering import clu_action\n",
    "from keywords import kw_action\n",
    "import json\n",
    "\n",
    "config = json.load(open('config.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection\n",
    "\n",
    "Select a subset of the dataset. Then the selected subset will be split into a training and a testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose the subset of data to workon on:\n",
      "l for all labeled samples\n",
      "k for samples of families mydoom, gepys, lamer, neshta, bladabindi, flystudio, eorezo\n",
      "s for 8 samples of families mydoom, gepys, bladabindi, flystudio\n",
      "f for a single family\n",
      "b for a balanced subset of samples\n",
      "q to quit\n",
      "k\n",
      "\n",
      "967 train samples belonging to 7 malware families\n",
      "Malware family:        eorezo        Number of samples:  219  \n",
      "Malware family:      bladabindi      Number of samples:  218  \n",
      "Malware family:        neshta        Number of samples:  184  \n",
      "Malware family:        mydoom        Number of samples:  116  \n",
      "Malware family:        lamer         Number of samples:  101  \n",
      "Malware family:      flystudio       Number of samples:   70  \n",
      "Malware family:        gepys         Number of samples:   59  \n",
      "\n",
      "242 test samples belonging to 7 malware families\n",
      "Malware family:      bladabindi      Number of samples:   51  \n",
      "Malware family:        eorezo        Number of samples:   47  \n",
      "Malware family:        neshta        Number of samples:   46  \n",
      "Malware family:        lamer         Number of samples:   35  \n",
      "Malware family:        mydoom        Number of samples:   30  \n",
      "Malware family:        gepys         Number of samples:   17  \n",
      "Malware family:      flystudio       Number of samples:   16  \n",
      "\n",
      "\n",
      "         family  fam_num  selected  train   test\n",
      "count     58180  58180.0    1209.0  967.0  242.0\n",
      "unique     1270   1270.0       NaN    NaN    NaN\n",
      "top     allaple     42.0       NaN    NaN    NaN\n",
      "freq      10569  10569.0       NaN    NaN    NaN\n",
      "mean        NaN      NaN       1.0    1.0    1.0\n",
      "std         NaN      NaN       0.0    0.0    0.0\n",
      "min         NaN      NaN       1.0    1.0    1.0\n",
      "25%         NaN      NaN       1.0    1.0    1.0\n",
      "50%         NaN      NaN       1.0    1.0    1.0\n",
      "75%         NaN      NaN       1.0    1.0    1.0\n",
      "max         NaN      NaN       1.0    1.0    1.0\n"
     ]
    }
   ],
   "source": [
    "samples_data = pp_action.pre_process(config)\n",
    "pp_action.split_show_data(samples_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "\n",
    "Currently each data vector has approximately 300.000 components. This usually creates problems during the clustering phase. Therefore, before going ahead to clustering the data, we proceed to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select a dimensionality reduction technique:\n",
      "pca\n",
      "svd\n",
      "tsne\n",
      "lda\n",
      "s to skip dimensionality reduction\n",
      "q to quit\n",
      "pca\n",
      "Please select the desired number of components (q to quit)\n",
      "100\n",
      "Performing dimensionality reduction using PCA\n",
      "Processing documents from 0 to 299\n",
      "Loading Tf-Idf of 300 documents\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "(300, 297360)\n",
      "Processing documents from 300 to 599\n",
      "Loading Tf-Idf of 300 documents\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "(300, 297360)\n",
      "Processing documents from 600 to 899\n",
      "Loading Tf-Idf of 300 documents\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "(300, 297360)\n",
      "Processing documents from 900 to 1199\n",
      "Loading Tf-Idf of 300 documents\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "(300, 297360)\n",
      "Processing documents from 1200 to 1499\n",
      "Loading Tf-Idf of 9 documents\n",
      "4757760\n",
      "7136640\n",
      "4757760\n",
      "4757760\n",
      "(9, 297360)\n",
      "Explained Variance Ratio\n",
      "0.827821550579\n",
      "Transforming documents from 0 to 299\n",
      "Loading Tf-Idf of 300 documents\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "(300, 297360)\n",
      "Transforming documents from 300 to 599\n",
      "Loading Tf-Idf of 300 documents\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "(300, 297360)\n",
      "Transforming documents from 600 to 899\n",
      "Loading Tf-Idf of 300 documents\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "(300, 297360)\n",
      "Transforming documents from 900 to 1199\n",
      "Loading Tf-Idf of 300 documents\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "178416000\n",
      "(300, 297360)\n",
      "Transforming documents from 1200 to 1499\n",
      "Loading Tf-Idf of 9 documents\n",
      "4757760\n",
      "4757760\n",
      "4757760\n",
      "7136640\n",
      "(9, 297360)\n"
     ]
    }
   ],
   "source": [
    "reduced, dr_model = dr_action.dimensionality_reduction(samples_data, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "Once the data dimensionality has been reduced we can proceed with clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select a clustering technique:\n",
      "kmeans for standard KMeans on feature selected data-set\n",
      "mini_kmeans for mini batch KMeans\n",
      "hdbscan for HDBSCAN \n",
      "spectral for Spectral clustering using Jensen-Shannon metric\n",
      "dbscan for DBSCAN clustering using Jensen-Shannon metric\n",
      "s to skip clustering/classification\n",
      "q to quit\n",
      "hdbscan\n",
      "\n",
      "Please select the desired metric\n",
      "e for euclidean\n",
      "c for cosine\n",
      "j for jensen-shannonq to quit\n",
      "c\n",
      "\n",
      "Would you like to use all the data as a sparse matrix? [y/n]\n",
      "It may take very long, depending on the number of selected samples\n",
      "n\n",
      "Please select the desired training matrix file (q to quit)\n",
      "data/d_matrices/pca_100_1209.txt\n",
      "Perform clustering with cosine distance\n",
      "(1209, 1209)\n",
      "--------------------------------------------------------------------------------\n",
      "Clustering evaluation\n",
      "Number of clusters 7\n",
      "Number of distinct families 7\n",
      "Adjusted Rand index: 0.558976629099\n",
      "Adjusted Mutual Information: 0.682123950781\n",
      "Fowlkes-Mallows: 0.630230675167\n",
      "Homogeneity: 0.732853336399\n",
      "Completeness: 0.684979660624\n",
      "BCubed Precision: 0.660564628224\n",
      "BCubed Recall: 0.749517421002\n",
      "BCubed FScore: 0.702235301589\n",
      "Silhouette 0.681474354098\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "clustering, clu_model = clu_action.cluster(samples_data, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hdbscan.plots.CondensedTree at 0x7f4e02d05c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clu_model.condensed_tree_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
