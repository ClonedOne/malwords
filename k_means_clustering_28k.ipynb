{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means clustering result analysis\n",
    "\n",
    "We will start our exploration of the dataset with one of the most classical clustering algorithms: K-Means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from keywords import kw_keyword_tfidf\n",
    "from sklearn.externals import joblib\n",
    "from preprocessing import pp_action\n",
    "from visualization import vis_data\n",
    "from clustering import clu_kmeans\n",
    "from utilities import evaluation\n",
    "from utilities import constants\n",
    "import plotly.offline as ply\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('config.json', 'r'))\n",
    "uuids_family = json.load(open(os.path.join(constants.dir_d, constants.json_labels), 'r'))\n",
    "words = json.load(open(os.path.join(constants.dir_d, constants.json_words), 'r'))\n",
    "ply.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection\n",
    "\n",
    "Select a subset of the original dataset. Then the selected subset will be split into a training and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_data = pp_action.pre_process(config)\n",
    "pp_action.split_show_data(samples_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uuids = samples_data.index[samples_data['selected'] == 1].tolist()\n",
    "numerical_labels = samples_data.fam_num[samples_data['selected'] == 1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Now that we have our data subset we can start with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_matrix = np.loadtxt('data/matrix/pca_1024_28582.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clustering_labels, model, modifier, data, metric = clu_kmeans.cluster(\n",
    "                data_matrix,\n",
    "                numerical_labels,\n",
    "                config,\n",
    "                {\n",
    "                    'num_clusters': 130,\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluation.evaluate_clustering(numerical_labels, clustering_labels, data, metric, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis\n",
    "\n",
    "To better understand the result of the clustering algorithm we would like to see the features characterizing the computed clusters. \n",
    "\n",
    "Since the dataset dimensionality was reduced with PCA before clustering we would need to reverse this step to understand the characteristics of the obtained clusters.\n",
    "\n",
    "To achieve this we will compute the centroids as the average of the data for each cluster and then multiply it by the transposed components matrix.\n",
    "\n",
    "We will start by creating an inverted index of the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr_model = joblib.load(os.path.join(constants.dir_d, constants.dir_mod, 'pca_1024_28582.pkl')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_clustering = defaultdict(list)\n",
    "for i in range(len(uuids)):\n",
    "    inverted_clustering[clustering_labels[i]].append(uuids[i])\n",
    "\n",
    "reduced_df = pd.DataFrame(data_matrix, index=uuids)\n",
    "centroids = {label : np.zeros(len(data_matrix[0])) for label in sorted(set(clustering_labels))}\n",
    "\n",
    "i = 0\n",
    "for index, vector in reduced_df.iterrows():\n",
    "    centroids[clustering_labels[i]] += vector.values\n",
    "    i += 1\n",
    "\n",
    "centroid_matrix = []\n",
    "for centroid in sorted(centroids.keys()):\n",
    "    centroids[centroid] /= len(inverted_clustering[centroid])\n",
    "    centroid_matrix.append(centroids[centroid])\n",
    "    \n",
    "centroid_matrix = np.array(centroid_matrix)\n",
    "centroids_orig_fts = np.dot(centroid_matrix, dr_model.components_)\n",
    "centroids_orig_fts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = dict(zip(range(len(words)), sorted(words.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "for centroid in centroids_orig_fts:\n",
    "    cent_series = pd.Series(np.abs(centroid), index=sorted(words.values()))\n",
    "    \n",
    "    print('Centroid {}:'.format(i))\n",
    "    print(cent_series.nlargest(10))\n",
    "    print()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_compositions = {i: Counter() for i in sorted(set(clustering_labels.flatten()))}\n",
    "\n",
    "for i in range(len(uuids)):\n",
    "    clust_compositions[clustering_labels[i]][uuids_family[uuids[i]]] += 1\n",
    "\n",
    "for clu in sorted(clust_compositions.keys()):\n",
    "    print('Cluster {}:'.format(clu))\n",
    "    print(clust_compositions[clu].most_common())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "families = samples_data.family[samples_data['selected'] == 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis_data.plot_data('data/matrix/tsne_2_28582.txt', families)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis_data.plot_data('data/matrix/tsne_2_28582.txt', clustering_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
